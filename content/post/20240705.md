---
title: "Diffusion 模型 Vs. AR 模型; VLM (视觉语言模型) 中引入视觉信息的必要性;  SFT(Supervised Fine-Tuning) 训练数据规模和质量"
date: 2024-07-05T22:45:36+08:00
tags: ["Diffusion", "VLM", "SFT", "RLHF", "多模态"]
---

## 1. Diffusion 模型 Vs. AR 模型： Diffusion 模型在相同算力下是否严格优于 AR 模型？
* **算力相等，结构不同**: 100 次 1B Diffusion 等价于特定结构的 100B 模型前向一次，效果取决于结构适配度。
* **Diffusion 的优势**:  Diffusion 模型利用 ODE/SDE 数学性质，对模型规模缩放的影响较大。
* **AR 模型的优势**: AR 模型易于扩展序列长度，符合人类逐步输出的规律。
* **争议**: Diffusion 模型的 100 步存在冗余，单步生成并非不可能。
* 相关引用：
    * **文章**: [Score-Based Generative Modeling through Stochastic Differential Equations](https://proceedings.neurips.cc/paper_files/paper/2023/file/80fe51a7d8d0c73ff7439c2a2554ed53-Paper-Conference.pdf)


## 2.  VLM (视觉语言模型) 中引入视觉信息的必要性
* **MMMU 数据集**:  部分人士认为 MMMU 数据集无需视觉信息，但高质量视觉信息对模型效果提升显著。
* **模型规模**:  现有开源多模态模型规模较小，瓶颈主要在 LLM 端，而非视觉端，导致视觉信息作用不明显。
* **相关测试**: 建议使用 MMMU 完整测试集进行评估，验证集数据量过小，结果不稳定。

## 3.  SFT(Supervised Fine-Tuning) 训练数据规模和质量
* **数据规模**:  早期观点认为 SFT 数据需少而精，但近期研究表明百万级数据量能带来更好效果。
* **质量控制**:  数据量增多时，如何控制数据质量和分布成为难题。
* **Llama 3**:  Llama 3 在 SFT 阶段使用了大量开源数据和人工标注数据。

## 4.  SFT 训练阶段的评估指标
* **Loss 下降**:  SFT 阶段每个 Epoch 的 Loss 都在下降，仅凭 Loss 下降难以评估模型效果。
* **评测成本**:  使用评测榜单数据评估每个 Checkpoint 成本高昂。
* **替代指标**:  缺乏有效的 SFT 阶段评估指标。

## 5.  RLHF(Reinforcement Learning from Human Feedback) 的未来方向
* **抽象问题**:  RLHF 的未来发展方向是什么？
* **相关讨论**:  知乎文章 [RLHF 的上界是什么](https://zhuanlan.zhihu.com/p/705910006?utm_psn=1789982041019932672) 引发讨论。

## 6.  代码生成模型 Code Llama 
* **规模**:  Code Llama 项目团队仅有 12 人，规模较小。
* **验证方法**:  使用 pass-list-eval 验证 non-inter-procedural pass 的正确性，可以考虑使用 translation validation 进行验证。
* **相关链接**: [https://github.com/AliveToolkit/alive2](https://github.com/AliveToolkit/alive2)

## 7.  开源模型的价值
* **代码价值**:  是否应该将代码实现视为开源模型价值的一部分？
* **信息提炼**:  论文本身是否已经足够"实在"，将最有价值的部分提炼出来？
* **观点**:  开源与不开源都有其合理性，取决于具体情况。


## 8.  LLM 推理系统 Mooncake
* **开源**:  月之暗面开源 Kimi 底层推理系统方案 Mooncake。
* **特性**:  以 KVCache 为中心的分布式架构。
* **相关链接**:  [https://github.com/kvcache-ai/Mooncake](https://github.com/kvcache-ai/Mooncake)


## 9.  多图理解
* **多图长文档理解**:  现有模型在多图长文档理解方面能力较差，无法准确识别图像数量。
* **图像中信息的感知**:  模型对图像中插入信息的感知能力不足。
* **数据有效性**:  图文交错数据对提升图文交错文档的理解能力效果不明显。
* **相关项目**:  [MM-NIAH](https://mm-niah.github.io/) 多模态大海捞针 Benchmark。

## 10.  检测文本是否是代码的工具
* **Guesslang**:  已停止维护，与 TensorFlow 不兼容。
* **Doc2x**:  商业模型，效果较好，提供 API 和免费额度。


## 争议点：
1. **模型参数量级与能力的关系**:  模型参数量级是否与能力直接相关？视觉模型参数量级较小是否因为视觉信息量更少？
2. **在线 vs 离线奖励模型训练**:  在线训练效果上限更高但需要更多数据，重要性采样能否替代在线训练？
3. **开源模型的定义**:  开源模型是否应该包括训练数据和训练过程？


##  Quick Points：
1.  Nexa AI 和 MIT-IBM Watson AI Lab 合作推出 Octo-planner，用于解决复杂任务的 AI Agent Workflow，在手机场景下实现了 97% 的成功率。
2.  DeepMind 利用 AlphaGo 中的 MCTS 算法训练 PRM for math，相关论文：https://arxiv.org/abs/2406.06592
3.  OpenAI 推出 CriticGPT 项目，利用 GPT-4 查找 GPT-4 错误。
4.  Google 发布 Gemma2，包含 9B 和 27B 两个版本。
5.  Meta 发布 Kimi 底层推理系统方案 Mooncake。
6.  Apple 发布机器学习平台 AXLearn。
7.  Nvidia 发布 SFT 数据集 Daring-Anteater。
8.  BAAI 发布 SFT 数据集 Infinity-Instruct。
9.  Huggingface 上部分模型存在问题，例如 Gemma2-27B-it。
10.  ChatGPT/Claude/Kimi 仍然可以套出系统提示词。